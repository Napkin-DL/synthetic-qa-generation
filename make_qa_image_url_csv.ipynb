{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate QnA synthetic dataset from CSV, containing Image URL\n",
    "\n",
    "This is another common case. If image url information is included, change this url to a summary result for that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Read & Preprocess CSV file\n",
    "---\n",
    "\n",
    "Read multiple csv files into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, shutil, random\n",
    "from unstructured.cleaners.core import clean_bullets, clean_extra_whitespace, remove_punctuation\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader, UnstructuredMarkdownLoader, UnstructuredAPIFileLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader, UnstructuredCSVLoader\n",
    "from util.preprocess import convert_html_to_md\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "raw_data_dir = \"raw_data\"\n",
    "csv_path = f\"{raw_data_dir}/cs-self-solve-web\"\n",
    "all_files = glob.glob(os.path.join(csv_path, \"*_modified.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>image_info</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소리가 작게 전달...</td>\n",
       "      <td>갤럭시 스마트폰의 전화 통화 시 송화음  수화음이 잘 전달되지 않거나 들리지 않는 ...</td>\n",
       "      <td>{'갤럭시 S23/S23+ 마이크 및 에어 벤트 홈 위치': 'https://api...</td>\n",
       "      <td>title : 갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다.</td>\n",
       "      <td>갤럭시 S24 시리즈의 보호 필름의 패키지 구성은 보호 필름(2매)  어플리케이터(...</td>\n",
       "      <td>{'S24 보호필름 박스 전면 이미지': 'https://api.samsungsvc...</td>\n",
       "      <td>title : 갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다., conte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소리가 작게 전달...   \n",
       "1                    갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다.   \n",
       "\n",
       "                                             content  \\\n",
       "0  갤럭시 스마트폰의 전화 통화 시 송화음  수화음이 잘 전달되지 않거나 들리지 않는 ...   \n",
       "1  갤럭시 S24 시리즈의 보호 필름의 패키지 구성은 보호 필름(2매)  어플리케이터(...   \n",
       "\n",
       "                                          image_info  \\\n",
       "0  {'갤럭시 S23/S23+ 마이크 및 에어 벤트 홈 위치': 'https://api...   \n",
       "1  {'S24 보호필름 박스 전면 이미지': 'https://api.samsungsvc...   \n",
       "\n",
       "                                             Content  \n",
       "0  title : 갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소...  \n",
       "1  title : 갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다., conte...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a base64 image input format that can be recognized by multimodal models such as GPT-4o.\n",
    "\n",
    "- Download the image (http://xyz.com/a.jpg)\n",
    "- Convert to image to base64 encoded strin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from util.preprocess import encode_url_image_base64\n",
    "\n",
    "def encode_images(img_dict):\n",
    "    return [encode_url_image_base64(v) for k, v in img_dict.items()]\n",
    "\n",
    "img_dict = eval(df['image_info'][0])\n",
    "df['image_info'] = df['image_info'].apply(lambda x: eval(x))  \n",
    "df['image_base64'] = df['image_info'].apply(encode_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>image_info</th>\n",
       "      <th>Content</th>\n",
       "      <th>image_base64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소리가 작게 전달...</td>\n",
       "      <td>갤럭시 스마트폰의 전화 통화 시 송화음  수화음이 잘 전달되지 않거나 들리지 않는 ...</td>\n",
       "      <td>{'갤럭시 S23/S23+ 마이크 및 에어 벤트 홈 위치': 'https://api...</td>\n",
       "      <td>title : 갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소...</td>\n",
       "      <td>[iVBORw0KGgoAAAANSUhEUgAAArwAAAINCAIAAABTTjvEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다.</td>\n",
       "      <td>갤럭시 S24 시리즈의 보호 필름의 패키지 구성은 보호 필름(2매)  어플리케이터(...</td>\n",
       "      <td>{'S24 보호필름 박스 전면 이미지': 'https://api.samsungsvc...</td>\n",
       "      <td>title : 갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다., conte...</td>\n",
       "      <td>[iVBORw0KGgoAAAANSUhEUgAAAMgAAAG0CAYAAAB3z2iQA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소리가 작게 전달...   \n",
       "1                    갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다.   \n",
       "\n",
       "                                             content  \\\n",
       "0  갤럭시 스마트폰의 전화 통화 시 송화음  수화음이 잘 전달되지 않거나 들리지 않는 ...   \n",
       "1  갤럭시 S24 시리즈의 보호 필름의 패키지 구성은 보호 필름(2매)  어플리케이터(...   \n",
       "\n",
       "                                          image_info  \\\n",
       "0  {'갤럭시 S23/S23+ 마이크 및 에어 벤트 홈 위치': 'https://api...   \n",
       "1  {'S24 보호필름 박스 전면 이미지': 'https://api.samsungsvc...   \n",
       "\n",
       "                                             Content  \\\n",
       "0  title : 갤럭시 S23  전화 통화 시 상대방 목소리가 작게 들리거나 내 목소...   \n",
       "1  title : 갤럭시 S24 시리즈  보호필름 부착 방법이 궁금합니다., conte...   \n",
       "\n",
       "                                        image_base64  \n",
       "0  [iVBORw0KGgoAAAANSUhEUgAAArwAAAINCAIAAABTTjvEA...  \n",
       "1  [iVBORw0KGgoAAAANSUhEUgAAAMgAAAG0CAYAAAB3z2iQA...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Summarization using GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=700,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4o\"                       \n",
    ")\n",
    "\n",
    "system_prompt = \"You are an AI assistant tasked with describing table or image, specialized in IT devices and mobile phone products.\"\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "human_prompt = [\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": \"data:image/png;base64,\" + \"{image_base64}\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": '''Given image, give a concise summary in Korean. Don't insert any XML tag such as <text> and </text> when answering.'''\n",
    "    },\n",
    "]\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_template,\n",
    "        human_message_template\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarize_chain = prompt | llm | StrOutputParser()\n",
    "#summarize_chain = {\"image_base64\": lambda x:x} | prompt | llm_text | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['image_summary'] = df['image_base64'].apply(lambda x: summarize_chain.batch(eval(x), {\"max_concurrency\": 5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{csv_path}/cs-self-solve.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{csv_path}/cs-self-solve.csv\")\n",
    "df['image_info'] = df['image_info'].apply(lambda x: eval(x))\n",
    "df['image_base64'] = df['image_base64'].apply(lambda x: eval(x))  \n",
    "df['image_summary'] = df['image_summary'].apply(lambda x: eval(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_final_context(x):\n",
    "\n",
    "    context =  f\"### Title:\\n{x['title']}\\n\\n### Context:\\n{x['content']}\\n\\n### Image:\\n\"\n",
    "\n",
    "    for idx, ((k,v), summary) in enumerate(zip(x['image_info'].items(), x['image_summary'])):\n",
    "        context += f'<image>{idx+1}번째 이미지 - {k}: {summary}</image>' + '\\n'\n",
    "    context = re.sub(' +', ' ', context)\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_context'] = df.apply(get_final_context, axis=1)\n",
    "preprocessed_docs = df['final_context'].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct QnA Pairs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from util.qa_pair import get_qna_repair_self_prompt_template, QAPair\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0.1, \n",
    "    max_tokens=1500,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4o\"                       \n",
    ")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=QAPair)\n",
    "\n",
    "prompt = get_qna_repair_self_prompt_template()\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = []\n",
    "\n",
    "for doc in preprocessed_docs:\n",
    "    dic = {\"context\": doc, \"domain\": \"Samsung Galaxy S series Smartphone\", \"num_questions\": \"4\"}\n",
    "    input_batch.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 302 ms, sys: 56.6 ms, total: 359 ms\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qa_pair = chain.batch(input_batch, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save to jsonl for fine-tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from util.common_utils import convert_to_oai_format, save_jsonl\n",
    "\n",
    "output_dir = './dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "system_prompt_msg = \"\"\"You are an AI assistant that provides guidance to help users self-service resolve abnormalities in their Galaxy mobile phone.\\n\n",
    "Please answer the questions accurately. If the question is in Korean, write your answer in Korean. If the question is in English, write your answer in English.\"\"\"\n",
    "\n",
    "save_filename = \"cs-self-solve\"\n",
    "oai_qa_pair = convert_to_oai_format(qa_pair)\n",
    "\n",
    "save_jsonl(qa_pair, f\"{output_dir}/{save_filename}.jsonl\")\n",
    "save_jsonl(oai_qa_pair, f\"{output_dir}/{save_filename}-oai.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
