{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate QnA synthetic dataset from a Complex PDF using Azure AI Document Intelligence\n",
    "\n",
    "### Overview\n",
    "We process the PDF by dividing it into three parts.\n",
    "\n",
    "- **Text-heavy** - Text-heavy PDF can be processed with open source without the need to use toolkits like Azure AI Document Intelligence or Unstructured.\n",
    "- **Image-heavy** - Image-heavy PDF can be converted the entire page to images and let a multimodal LLM like GPT-4o summarize each page.\n",
    "- **Mixed** - After reading the document with Azure AI Document Intelligence, we replace the image descriptions inside the figure tags with text summarized by a multimodal LLM. (Often the image descriptions are blank or have only a short caption.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read & Preprocess PDF file\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the PDFs into individual pages\n",
    "Only use a poration of the PDF documents for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version    = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://oai-daekeun.openai.azure.com/',\n",
       " '9339425b4aa54e2080397e677003ce8f',\n",
       " '2024-05-01-preview')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"AZURE_OPENAI_ENDPOINT\"), os.getenv(\"AZURE_OPENAI_API_KEY\"), os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m1. 모니터가 너무 뜨거워. 2. 모니터가 시장 반응이 너무 뜨거워.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Simple API Call\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCreate a taxonomy of human knowledge and capabilities. Break it down into fields, sub-fields, and disciplines.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# messages=[\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     {\"role\": \"system\", \"content\": system_message},\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     {\"role\": \"user\", \"content\": user_message},\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ]\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/openai/_utils/_utils.py:276\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given"
     ]
    }
   ],
   "source": [
    "# Create your first prompt\n",
    "system_message = \"\"\"너는 긍정과 부정을 구분할 수 있는 에이전트야. 결과는 JSON 형식으로 공백 없이 반환해줘. 답변 예:{\"1\": \"긍정\", \"2\": \"부정\"}\"\"\"\n",
    "user_message = \"\"\"1. 모니터가 너무 뜨거워. 2. 모니터가 시장 반응이 너무 뜨거워.\"\"\"\n",
    "\n",
    "# Simple API Call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    max_tokens=60,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an AI assistant good at generating Synthetic QnA.\"\n",
    "prompt = \"\"\"\n",
    "Create a taxonomy of human knowledge and capabilities in JSON format. Break it down into fields, sub-fields, and disciplines. Response must be Korean language.\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"지식과 능력의 분류\": {\n",
      "    \"자연과학\": {\n",
      "      \"물리학\": {\n",
      "        \"고전물리학\": {},\n",
      "        \"양자물리학\": {},\n",
      "        \"상대성이론\": {}\n",
      "      },\n",
      "      \"화학\": {\n",
      "        \"분석화학\": {},\n",
      "        \"유기화학\": {},\n",
      "        \"물리화학\": {}\n",
      "      },\n",
      "      \"생물학\": {\n",
      "        \"세포생물학\": {},\n",
      "        \"유전학\": {},\n",
      "        \"생태학\": {}\n",
      "      },\n",
      "      \"지구과학\": {\n",
      "        \"지질학\": {},\n",
      "        \"기상학\": {},\n",
      "        \"천문학\": {}\n",
      "      }\n",
      "    },\n",
      "    \"공학\": {\n",
      "      \"기계공학\": {\n",
      "        \"열역학\": {},\n",
      "        \"로봇공학\": {},\n",
      "        \"재료공학\": {}\n",
      "      },\n",
      "      \"전기공학\": {\n",
      "        \"전자공학\": {},\n",
      "        \"네트워크공학\": {},\n",
      "        \"제어공학\": {}\n",
      "      },\n",
      "      \"화학공학\": {\n",
      "        \"공정공학\": {},\n",
      "        \"재료공학\": {},\n",
      "        \"에너지공학\": {}\n",
      "      },\n",
      "      \"생명공학\": {\n",
      "        \"유전자공학\": {},\n",
      "        \"생체재료학\": {},\n",
      "        \"생의학공학\": {}\n",
      "      }\n",
      "    },\n",
      "    \"인문학\": {\n",
      "      \"문학\": {\n",
      "        \"고전문학\": {},\n",
      "        \"현대문학\": {},\n",
      "        \"비평문학\": {}\n",
      "      },\n",
      "      \"역사학\": {\n",
      "        \"고대사\": {},\n",
      "        \"중세사\": {},\n",
      "        \"근현대사\": {}\n",
      "      },\n",
      "      \"철학\": {\n",
      "        \"형이상학\": {},\n",
      "        \"윤리학\": {},\n",
      "        \"논리학\": {}\n",
      "      },\n",
      "      \"언어학\": {\n",
      "        \"구조주의언어학\": {},\n",
      "        \"역사언어학\": {},\n",
      "        \"사회언어학\": {}\n",
      "      }\n",
      "    },\n",
      "    \"사회과학\": {\n",
      "      \"심리학\": {\n",
      "        \"발달심리학\": {},\n",
      "        \"임상심리학\": {},\n",
      "        \"사회심리학\": {}\n",
      "      },\n",
      "      \"사회학\": {\n",
      "        \"문화사회학\": {},\n",
      "        \"경제사회학\": {},\n",
      "        \"정치사회학\": {}\n",
      "      },\n",
      "      \"경제학\": {\n",
      "        \"거시경제학\": {},\n",
      "        \"미시경제학\": {},\n",
      "        \"국제경제학\": {}\n",
      "      },\n",
      "      \"정치학\": {\n",
      "        \"정치이론\": {},\n",
      "        \"비교정치학\": {},\n",
      "        \"국제관계학\": {}\n",
      "      }\n",
      "    },\n",
      "    \"예술\": {\n",
      "      \"시각예술\": {\n",
      "        \"회화\": {},\n",
      "        \"조각\": {},\n",
      "        \"그래픽디자인\": {}\n",
      "      },\n",
      "      \"공연예술\": {\n",
      "        \"연극\": {},\n",
      "        \"무용\": {},\n",
      "        \"음악\": {}\n",
      "      },\n",
      "      \"문학예술\": {\n",
      "        \"시\": {},\n",
      "        \"소설\": {},\n",
      "        \"희곡\": {}\n",
      "      },\n",
      "      \"미디어예술\": {\n",
      "        \"영화\": {},\n",
      "        \"텔레비전\": {},\n",
      "        \"비디오게임\": {}\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = response.choices[0].message.content\n",
    "try:\n",
    "\n",
    "    taxonomy_json = json.loads(taxonomy)\n",
    "except json.JSONDecodeError:\n",
    "    taxonomy_json = {\"error\": \"Failed to parse JSON\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'지식과 능력의 분류': {'자연과학': {'물리학': {'고전물리학': {}, '양자물리학': {}, '상대성이론': {}},\n",
       "   '화학': {'분석화학': {}, '유기화학': {}, '물리화학': {}},\n",
       "   '생물학': {'세포생물학': {}, '유전학': {}, '생태학': {}},\n",
       "   '지구과학': {'지질학': {}, '기상학': {}, '천문학': {}}},\n",
       "  '공학': {'기계공학': {'열역학': {}, '로봇공학': {}, '재료공학': {}},\n",
       "   '전기공학': {'전자공학': {}, '네트워크공학': {}, '제어공학': {}},\n",
       "   '화학공학': {'공정공학': {}, '재료공학': {}, '에너지공학': {}},\n",
       "   '생명공학': {'유전자공학': {}, '생체재료학': {}, '생의학공학': {}}},\n",
       "  '인문학': {'문학': {'고전문학': {}, '현대문학': {}, '비평문학': {}},\n",
       "   '역사학': {'고대사': {}, '중세사': {}, '근현대사': {}},\n",
       "   '철학': {'형이상학': {}, '윤리학': {}, '논리학': {}},\n",
       "   '언어학': {'구조주의언어학': {}, '역사언어학': {}, '사회언어학': {}}},\n",
       "  '사회과학': {'심리학': {'발달심리학': {}, '임상심리학': {}, '사회심리학': {}},\n",
       "   '사회학': {'문화사회학': {}, '경제사회학': {}, '정치사회학': {}},\n",
       "   '경제학': {'거시경제학': {}, '미시경제학': {}, '국제경제학': {}},\n",
       "   '정치학': {'정치이론': {}, '비교정치학': {}, '국제관계학': {}}},\n",
       "  '예술': {'시각예술': {'회화': {}, '조각': {}, '그래픽디자인': {}},\n",
       "   '공연예술': {'연극': {}, '무용': {}, '음악': {}},\n",
       "   '문학예술': {'시': {}, '소설': {}, '희곡': {}},\n",
       "   '미디어예술': {'영화': {}, '텔레비전': {}, '비디오게임': {}}}}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an AI assistant good at generating Synthetic QnA.\"\n",
    "# Taxonomy 생성 함수\n",
    "def generate_taxonomy():\n",
    "    prompt = \"\"\"\n",
    "    Create a taxonomy of human knowledge and capabilities. Break it down into fields, sub-fields, and disciplines.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        max_tokens=60,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    # taxonomy = response.choices[0].text.strip()\n",
    "    # try:\n",
    "    #     taxonomy_json = json.loads(taxonomy)\n",
    "    # except json.JSONDecodeError:\n",
    "    #     taxonomy_json = {\"error\": \"Failed to parse JSON\"}\n",
    "    # return taxonomy_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subjects(discipline):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in {discipline}. Create a comprehensive list of subjects a student should learn under this discipline. \n",
    "    For each subject, provide the level (e.g., undergraduate, graduate) and include key subtopics. \n",
    "    Present the result in JSON format. Language must be Korean.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        max_tokens=100,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    subjects = re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_subjects(discipline):\n",
    "discipline = \"Computer Science\"\n",
    "prompt = f\"\"\"\n",
    "You are an expert in {discipline}. Create a comprehensive list of subjects a student should learn under this discipline. \n",
    "For each subject, provide the level (e.g., 100, 200, 300, 400, 500) and include key subtopics. \n",
    "Present the result in JSON format. \n",
    "For each subject s, it should be s.level, s.name and s.subtopics.\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    ")\n",
    "subjects = response.choices[0].message.content\n",
    "try:\n",
    "    subjects_json = json.loads(subjects)\n",
    "except json.JSONDecodeError:\n",
    "    subjects_json = {\"error\": \"Failed to parse JSON\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"subjects\": [\n",
      "    {\n",
      "      \"name\": \"Introduction to Computer Science\",\n",
      "      \"level\": 100,\n",
      "      \"subtopics\": [\n",
      "        \"Programming basics\",\n",
      "        \"Algorithms and Data Structures\",\n",
      "        \"Software Development Methodologies\",\n",
      "        \"Introduction to Databases\",\n",
      "        \"Basic Operating Systems Concepts\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Data Structures and Algorithms\",\n",
      "      \"level\": 200,\n",
      "      \"subtopics\": [\n",
      "        \"Arrays and Linked Lists\",\n",
      "        \"Stacks and Queues\",\n",
      "        \"Trees and Graphs\",\n",
      "        \"Sorting and Searching Algorithms\",\n",
      "        \"Big-O Notation and Complexity Analysis\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Object-Oriented Programming\",\n",
      "      \"level\": 200,\n",
      "      \"subtopics\": [\n",
      "        \"Classes and Objects\",\n",
      "        \"Inheritance and Polymorphism\",\n",
      "        \"Encapsulation and Abstraction\",\n",
      "        \"Design Patterns\",\n",
      "        \"Exception Handling\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Computer Architecture\",\n",
      "      \"level\": 300,\n",
      "      \"subtopics\": [\n",
      "        \"CPU Design\",\n",
      "        \"Memory Hierarchy\",\n",
      "        \"Input/Output Mechanisms\",\n",
      "        \"Instruction Set Architecture\",\n",
      "        \"Pipelining and Parallelism\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Operating Systems\",\n",
      "      \"level\": 300,\n",
      "      \"subtopics\": [\n",
      "        \"Process Management\",\n",
      "        \"Memory Management\",\n",
      "        \"File Systems\",\n",
      "        \"Concurrency and Synchronization\",\n",
      "        \"Security and Protection\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Database Management Systems\",\n",
      "      \"level\": 300,\n",
      "      \"subtopics\": [\n",
      "        \"Relational Databases\",\n",
      "        \"SQL and NoSQL\",\n",
      "        \"ER Diagrams\",\n",
      "        \"Normalization and Indexing\",\n",
      "        \"Transactions and Concurrency Control\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Software Engineering\",\n",
      "      \"level\": 300,\n",
      "      \"subtopics\": [\n",
      "        \"Software Development Lifecycle\",\n",
      "        \"Agile and Scrum Methodologies\",\n",
      "        \"Requirements Engineering\",\n",
      "        \"Software Design and Architecture\",\n",
      "        \"Testing and Maintenance\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Computer Networks\",\n",
      "      \"level\": 300,\n",
      "      \"subtopics\": [\n",
      "        \"Networking Protocols\",\n",
      "        \"OSI and TCP/IP Models\",\n",
      "        \"Network Topologies\",\n",
      "        \"Routing and Switching\",\n",
      "        \"Network Security\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Algorithms\",\n",
      "      \"level\": 400,\n",
      "      \"subtopics\": [\n",
      "        \"Advanced Sorting and Searching\",\n",
      "        \"Graph Algorithms\",\n",
      "        \"Dynamic Programming\",\n",
      "        \"Greedy Algorithms\",\n",
      "        \"NP-Hard and NP-Complete Problems\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Artificial Intelligence\",\n",
      "      \"level\": 400,\n",
      "      \"subtopics\": [\n",
      "        \"Search Algorithms\",\n",
      "        \"Machine Learning\",\n",
      "        \"Natural Language Processing\",\n",
      "        \"Robotics\",\n",
      "        \"Expert Systems\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Compiler Design\",\n",
      "      \"level\": 400,\n",
      "      \"subtopics\": [\n",
      "        \"Lexical Analysis\",\n",
      "        \"Syntax Analysis\",\n",
      "        \"Semantic Analysis\",\n",
      "        \"Code Optimization\",\n",
      "        \"Code Generation\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Cyber Security\",\n",
      "      \"level\": 400,\n",
      "      \"subtopics\": [\n",
      "        \"Cryptography\",\n",
      "        \"Network Security\",\n",
      "        \"Application Security\",\n",
      "        \"Incident Response\",\n",
      "        \"Ethical Hacking\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Distributed Systems\",\n",
      "      \"level\": 400,\n",
      "      \"subtopics\": [\n",
      "        \"Fundamentals of Distributed Computing\",\n",
      "        \"Distributed Algorithms\",\n",
      "        \"Consistency and Replication\",\n",
      "        \"Fault Tolerance\",\n",
      "        \"Distributed Databases\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Human-Computer Interaction\",\n",
      "      \"level\": 500,\n",
      "      \"subtopics\": [\n",
      "        \"User-Centered Design\",\n",
      "        \"Usability Testing\",\n",
      "        \"Interaction Design\",\n",
      "        \"Cognitive Psychology\",\n",
      "        \"Interface Evaluation\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Advanced Machine Learning\",\n",
      "      \"level\": 500,\n",
      "      \"subtopics\": [\n",
      "        \"Deep Learning\",\n",
      "        \"Reinforcement Learning\",\n",
      "        \"Unsupervised Learning\",\n",
      "        \"Bayesian Methods\",\n",
      "        \"Model Evaluation and Selection\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Quantum Computing\",\n",
      "      \"level\": 500,\n",
      "      \"subtopics\": [\n",
      "        \"Quantum Mechanics Basics\",\n",
      "        \"Quantum Algorithms\",\n",
      "        \"Quantum Cryptography\",\n",
      "        \"Quantum Simulator\",\n",
      "        \"Quantum Machine Learning\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Data Science and Big Data\",\n",
      "      \"level\": 500,\n",
      "      \"subtopics\": [\n",
      "        \"Data Wrangling and Cleaning\",\n",
      "        \"Statistical Analysis\",\n",
      "        \"Data Visualization\",\n",
      "        \"Big Data Technologies\",\n",
      "        \"\n"
     ]
    }
   ],
   "source": [
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_syllabus(subject, level, subtopics):\n",
    "subject = \"Introduction to Computer Science\"\n",
    "level = \"100\"\n",
    "subtopics = [\"Basic Programming Concepts\", \"Algorithms and Data Structures\"]\n",
    "prompt = f\"\"\"\n",
    "You are an expert in creating educational syllabi. Create a detailed syllabus for the subject \"{subject}\" at the {level} level. \n",
    "The syllabus should be broken down into multiple class sessions, each covering different key concepts. \n",
    "The subtopics for this subject include: {subtopics}. Provide the syllabus in JSON format with the following structure:\n",
    "[\n",
    "    {{\n",
    "        \"session_name\": \"Session 1 Name\",\n",
    "        \"description\": \"Brief description of the session\",\n",
    "        \"key_concepts\": [\"Key concept 1\", \"Key concept 2\", ...]\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    max_tokens=2000,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    ")\n",
    "\n",
    "syllabus = response.choices[0].message.content\n",
    "try:\n",
    "    syllabus_json = json.loads(syllabus)\n",
    "except json.JSONDecodeError:\n",
    "    syllabus_json = {\"error\": \"Failed to parse JSON\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syllabus': [{'session_name': 'Introduction to Computer Science',\n",
       "   'description': 'Overview of computer science, its history, and its significance in modern society.',\n",
       "   'key_concepts': ['History of Computing',\n",
       "    'Branches of Computer Science',\n",
       "    'Impact of Computing on Society']},\n",
       "  {'session_name': 'Understanding Computers and Operating Systems',\n",
       "   'description': 'Introduction to computer hardware and software, basic understanding of operating systems.',\n",
       "   'key_concepts': ['Computer Hardware',\n",
       "    'Computer Software',\n",
       "    'Operating Systems']},\n",
       "  {'session_name': 'Introduction to Basic Programming Concepts',\n",
       "   'description': 'Introduction to basic programming concepts using a high-level programming language (e.g., Python).',\n",
       "   'key_concepts': ['Programming Languages',\n",
       "    'Syntax and Semantics',\n",
       "    'Basic Input/Output',\n",
       "    'Variables and Data Types']},\n",
       "  {'session_name': 'Control Structures in Programming',\n",
       "   'description': 'Understanding and using control structures like conditionals and loops.',\n",
       "   'key_concepts': ['Conditional Statements (if, else, elif)',\n",
       "    'Loops (for, while)',\n",
       "    'Nested Control Structures']},\n",
       "  {'session_name': 'Functions and Modular Programming',\n",
       "   'description': 'Introduction to functions and the importance of modular programming.',\n",
       "   'key_concepts': ['Defining Functions',\n",
       "    'Function Arguments and Return Values',\n",
       "    'Scope and Lifetime of Variables',\n",
       "    'Modular Programming']},\n",
       "  {'session_name': 'Introduction to Algorithms',\n",
       "   'description': 'Understanding algorithms and their role in problem-solving.',\n",
       "   'key_concepts': ['Definition of an Algorithm',\n",
       "    'Algorithm Efficiency (Time and Space Complexity)',\n",
       "    'Basic Algorithm Design Techniques']},\n",
       "  {'session_name': 'Data Structures: Arrays and Lists',\n",
       "   'description': 'Introduction to basic data structures like arrays and lists, their implementation, and usage.',\n",
       "   'key_concepts': ['Arrays',\n",
       "    'Lists',\n",
       "    'Operations on Arrays and Lists (insertion, deletion, traversal)']},\n",
       "  {'session_name': 'Data Structures: Stacks and Queues',\n",
       "   'description': 'Understanding stacks and queues, their implementation, and applications.',\n",
       "   'key_concepts': ['Stacks (LIFO)',\n",
       "    'Queues (FIFO)',\n",
       "    'Operations on Stacks and Queues',\n",
       "    'Applications of Stacks and Queues']},\n",
       "  {'session_name': 'Introduction to Sorting and Searching Algorithms',\n",
       "   'description': 'Overview of fundamental sorting and searching algorithms.',\n",
       "   'key_concepts': ['Bubble Sort',\n",
       "    'Selection Sort',\n",
       "    'Insertion Sort',\n",
       "    'Linear Search',\n",
       "    'Binary Search']},\n",
       "  {'session_name': 'Recursive Algorithms',\n",
       "   'description': 'Introduction to recursion, its mechanism, and examples of recursive algorithms.',\n",
       "   'key_concepts': ['Definition of Recursion',\n",
       "    'Base Case and Recursive Case',\n",
       "    'Examples of Recursive Algorithms (factorial, Fibonacci)']},\n",
       "  {'session_name': 'Introduction to Object-Oriented Programming',\n",
       "   'description': 'Understanding the principles of object-oriented programming (OOP).',\n",
       "   'key_concepts': ['Classes and Objects',\n",
       "    'Encapsulation',\n",
       "    'Inheritance',\n",
       "    'Polymorphism']},\n",
       "  {'session_name': 'Introduction to Files and Data Persistence',\n",
       "   'description': 'Understanding file handling and basic data persistence techniques.',\n",
       "   'key_concepts': ['Reading and Writing Files',\n",
       "    'File Modes and Functions',\n",
       "    'Data Persistence']},\n",
       "  {'session_name': 'Basic Concepts of Software Development',\n",
       "   'description': 'Overview of software development processes, methodologies, and best practices.',\n",
       "   'key_concepts': ['Software Development Life Cycle (SDLC)',\n",
       "    'Version Control Systems',\n",
       "    'Agile Methodology',\n",
       "    'Testing and Debugging']},\n",
       "  {'session_name': 'Ethics in Computing',\n",
       "   'description': 'Discussion on the ethical considerations in computing, including privacy, security, and ethical hacking.',\n",
       "   'key_concepts': ['Privacy and Security',\n",
       "    'Digital Ethics',\n",
       "    'Ethical Hacking']},\n",
       "  {'session_name': 'Final Project and Review',\n",
       "   'description': 'Review of key concepts and application of learnt knowledge in a final project.',\n",
       "   'key_concepts': ['Project Planning',\n",
       "    'Project Development',\n",
       "    'Presentation and Review']}]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllabus_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_name': 'Introduction to Computer Science',\n",
       " 'description': 'An overview of the field of computer science and its significance.',\n",
       " 'key_concepts': ['History of computer science',\n",
       "  'Applications of computer science',\n",
       "  'Introduction to hardware and software']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllabus_json['syllabus'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction to Computer Science'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllabus_json[\"syllabus\"][0][\"session_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Generate a homework question based on the following class session and key concepts\n",
      "    ====    \n",
      "    class session: Introduction to Computer Science\n",
      "    \n",
      "    key_concepts: ['History of computer science', 'Applications of computer science', 'Introduction to hardware and software']\n",
      "    ====\n",
      "    \n",
      "    The question should be challenging and cover multiple key concepts from the syllabus.\n",
      "    Language must be Korean. Output format must be text.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "num_questions = 2\n",
    "\n",
    "class_session = syllabus_json[\"syllabus\"][0][\"session_name\"]\n",
    "key_concepts = syllabus_json[\"syllabus\"][0][\"key_concepts\"]\n",
    "for _ in range(num_questions):\n",
    "    prompt = f\"\"\"\n",
    "    Generate a homework question based on the following class session and key concepts\n",
    "    ====    \n",
    "    class session: {class_session}\n",
    "    \n",
    "    key_concepts: {key_concepts}\n",
    "    ====\n",
    "    \n",
    "    The question should be challenging and cover multiple key concepts from the syllabus.\n",
    "    Language must be Korean. Output format must be text.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        max_tokens=2000,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    question = response.choices[0].message.content\n",
    "    questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "다음 질문에 답하십시오. \n",
      "\n",
      "---\n",
      "\n",
      "**문제:**\n",
      "\n",
      "컴퓨터 과학은 여러 가지 중요한 발전 단계를 거쳐 왔습니다. 아래에 제시된 개념들을 활용하여 다음 질문에 답변해 보세요.\n",
      "\n",
      "1. 컴퓨터 과학의 발전사를 간략히 설명하시오. 초기 컴퓨터의 등장부터 최근의 기술 발전까지 중요한 사건들을 포함하십시오.\n",
      "2. 오늘날 컴퓨터 과학이 다양한 분야에서 어떻게 응용되고 있는지에 대해 두 가지 사례를 들어 설명하시오. 사례 중 하나는 소프트웨어 응용에, 다른 하나는 하드웨어 발전에 초점을 맞추어 작성하시오.\n",
      "3. 하드웨어와 소프트웨어의 차이점을 정의하고, 각 요소가 컴퓨터 과학의 발전에 어떤 역할을 했는지 설명하시오.\n",
      "\n",
      "**힌트:**\n",
      "\n",
      "- 초기 컴퓨터로는 예를 들어, ENIAC과 같은 컴퓨터를 들 수 있습니다.\n",
      "- 소프트웨어 응용으로는 예를 들어, 인공지능이나 데이터 분석 등을 생각해 볼 수 있습니다.\n",
      "- 하드웨어의 발전으로는 예를 들어, 반도체 기술의 발전이나 퀀텀 컴퓨팅 등을 들 수 있습니다.\n",
      "\n",
      "답변은 500자 내외로 작성하십시오.\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(questions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Session Sampling:\n",
      " ('Session 2: Searching Algorithms', ['Depth-First Search', 'Binary Search'])\n",
      "Multi Session Sampling:\n",
      " (['Session 3: Graph Algorithms', 'Session 2: Searching Algorithms'], ['Breadth-First Search', 'Binary Search', \"Dijkstra's Algorithm\"])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#단일 세션 샘플링의 경우, 하나의 세션에서 1~5개의 핵심 개념을 무작위로 선택.\n",
    "#다중 세션 샘플링의 경우, 두 개의 세션에서 핵심 개념을 결합하고 2~5개의 핵심 개념을 무작위로 선택.\n",
    "\n",
    "def sample_class_sessions_and_key_concepts(class_sessions, key_concepts, single_session=True):\n",
    "    \"\"\"\n",
    "    클래스 세션과 핵심 개념을 샘플링하여 다양한 난이도의 질문을 생성합니다.\n",
    "    \n",
    "    :param class_sessions: 클래스 세션의 리스트\n",
    "    :param key_concepts: 각 세션에 대한 핵심 개념의 리스트\n",
    "    :param single_session: 단일 세션에서 샘플링할지 다중 세션에서 샘플링할지 여부\n",
    "    :return: 샘플링된 클래스 세션과 핵심 개념의 조합\n",
    "    \"\"\"\n",
    "    if single_session:\n",
    "        # 단일 세션에서 샘플링\n",
    "        session_index = random.randint(0, len(class_sessions) - 1)\n",
    "        selected_session = class_sessions[session_index]\n",
    "        num_concepts = min(5, len(key_concepts[session_index]))\n",
    "        selected_key_concepts = random.sample(key_concepts[session_index], k=random.randint(1, num_concepts))\n",
    "    else:\n",
    "        # 다중 세션에서 샘플링\n",
    "        if len(class_sessions) < 2:\n",
    "            raise ValueError(\"Not enough sessions for multi-session sampling\")\n",
    "        session_indices = random.sample(range(len(class_sessions)), k=2)\n",
    "        selected_sessions = [class_sessions[i] for i in session_indices]\n",
    "        combined_key_concepts = key_concepts[session_indices[0]] + key_concepts[session_indices[1]]\n",
    "        num_concepts = min(5, len(combined_key_concepts))\n",
    "        selected_key_concepts = random.sample(combined_key_concepts, k=random.randint(2, num_concepts))\n",
    "    \n",
    "    return selected_session if single_session else selected_sessions, selected_key_concepts\n",
    "\n",
    "# 예제 실행\n",
    "class_sessions = [\"Session 1: Sorting Algorithms\", \"Session 2: Searching Algorithms\", \"Session 3: Graph Algorithms\"]\n",
    "key_concepts = [\n",
    "    [\"Bubble Sort\", \"Merge Sort\", \"Quick Sort\"],\n",
    "    [\"Binary Search\", \"Depth-First Search\", \"Breadth-First Search\"],\n",
    "    [\"Dijkstra's Algorithm\", \"Floyd-Warshall Algorithm\", \"Kruskal's Algorithm\"]\n",
    "]\n",
    "\n",
    "# 단일 세션 샘플링\n",
    "single_session_result = sample_class_sessions_and_key_concepts(class_sessions, key_concepts, single_session=True)\n",
    "print(\"Single Session Sampling:\\n\", single_session_result)\n",
    "\n",
    "# 다중 세션 샘플링\n",
    "multi_session_result = sample_class_sessions_and_key_concepts(class_sessions, key_concepts, single_session=False)\n",
    "print(\"Multi Session Sampling:\\n\", multi_session_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syllabus': [{'session_name': 'Introduction to Computer Science',\n",
       "   'description': 'An overview of the field of computer science and its significance.',\n",
       "   'key_concepts': ['History of computer science',\n",
       "    'Applications of computer science',\n",
       "    'Introduction to hardware and software']},\n",
       "  {'session_name': 'Basics of Programming Languages',\n",
       "   'description': 'Introduction to different programming languages and their paradigms.',\n",
       "   'key_concepts': ['Types of programming languages',\n",
       "    'Programming paradigms',\n",
       "    'Hello World in multiple languages']},\n",
       "  {'session_name': 'Getting Started with Python',\n",
       "   'description': 'Setting up Python and writing first simple programs.',\n",
       "   'key_concepts': ['Installing Python',\n",
       "    'Python IDEs',\n",
       "    'Writing and running a basic Python script']},\n",
       "  {'session_name': 'Variables and Data Types',\n",
       "   'description': 'Understanding different data types and variables in Python.',\n",
       "   'key_concepts': ['Variables',\n",
       "    'Data types (int, float, str, bool)',\n",
       "    'Type conversion']},\n",
       "  {'session_name': 'Control Structures: Conditionals',\n",
       "   'description': 'How to control the flow of a program using conditional statements.',\n",
       "   'key_concepts': ['If statements',\n",
       "    'Else and elif statements',\n",
       "    'Nested conditionals']},\n",
       "  {'session_name': 'Control Structures: Loops',\n",
       "   'description': 'Introduction to loops and their usage in programming.',\n",
       "   'key_concepts': ['For loops',\n",
       "    'While loops',\n",
       "    'Break and continue statements']},\n",
       "  {'session_name': 'Functions: Definition and Usage',\n",
       "   'description': 'Understanding functions and how to use them.',\n",
       "   'key_concepts': ['Defining functions',\n",
       "    'Function arguments',\n",
       "    'Return values']},\n",
       "  {'session_name': 'Basic Data Structures: Lists and Tuples',\n",
       "   'description': 'An introduction to lists and tuples and their operations.',\n",
       "   'key_concepts': ['Lists', 'Tuples', 'List and tuple operations']},\n",
       "  {'session_name': 'Basic Data Structures: Dictionaries and Sets',\n",
       "   'description': 'Understanding dictionaries and sets and how to use them.',\n",
       "   'key_concepts': ['Dictionaries',\n",
       "    'Dictionary operations',\n",
       "    'Sets',\n",
       "    'Set operations']},\n",
       "  {'session_name': 'Introduction to Algorithms',\n",
       "   'description': 'A basic overview of algorithms and their importance in computer science.',\n",
       "   'key_concepts': ['What is an algorithm?',\n",
       "    'Algorithm efficiency',\n",
       "    'Basic algorithm examples']},\n",
       "  {'session_name': 'Sorting Algorithms',\n",
       "   'description': 'Introduction to common sorting algorithms and their implementations in Python.',\n",
       "   'key_concepts': ['Bubble sort', 'Selection sort', 'Insertion sort']},\n",
       "  {'session_name': 'Searching Algorithms',\n",
       "   'description': 'Understanding different searching algorithms and their applications.',\n",
       "   'key_concepts': ['Linear search', 'Binary search', 'Search efficiency']},\n",
       "  {'session_name': 'Recursion',\n",
       "   'description': 'Introduction to the concept of recursion and recursive programming.',\n",
       "   'key_concepts': ['What is recursion?',\n",
       "    'Base case and recursive case',\n",
       "    'Examples of recursive functions']},\n",
       "  {'session_name': 'Introduction to Object-Oriented Programming (OOP)',\n",
       "   'description': 'Basics of OOP concepts and their advantages.',\n",
       "   'key_concepts': ['Classes and objects',\n",
       "    'Attributes and methods',\n",
       "    'Inheritance and polymorphism']},\n",
       "  {'session_name': 'Basic OOP in Python',\n",
       "   'description': 'Implementing basic OOP concepts in Python.',\n",
       "   'key_concepts': ['Defining classes', 'Creating objects', 'Using methods']},\n",
       "  {'session_name': 'Data Structures: Stacks and Queues',\n",
       "   'description': 'Detailed exploration of stacks and queues.',\n",
       "   'key_concepts': ['Stack operations',\n",
       "    'Queue operations',\n",
       "    'Usage of stacks and queues']},\n",
       "  {'session_name': 'Data Structures: Linked Lists',\n",
       "   'description': 'Introduction to linked lists and their operations.',\n",
       "   'key_concepts': ['What is a linked list?',\n",
       "    'Singly linked list',\n",
       "    'Doubly linked list']},\n",
       "  {'session_name': 'Final Review and Project Presentation',\n",
       "   'description': 'Review of all topics covered and presentation of final projects.',\n",
       "   'key_concepts': ['Review of key concepts',\n",
       "    'Project presentations',\n",
       "    'Q&A session']}]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \t{\n",
      "        \"syllabus_question\": {\n",
      "            \"session_name\": \"Introduction to Algorithms, Control Structures: Conditionals, Control Structures: Loops, Functions: Definition and Usage\",\n",
      "            \"description\": \"여러 개념을 활용하여 문제를 해결하는 과제를 통해 학습한 내용을 종합적으로 복습하세요.\",\n",
      "            \"question\": \"주어진 정수 배열이 오름차순으로 정렬되어 있는지를 확인하는 Python 프로그램을 작성하세요. 이 프로그램은 다음과 같은 기능을 포함해야 합니다: \\n1. 배열을 입력받는 함수 (함수를 정의하고, 함수 인자를 활용하세요).\\n2. 배열의 각 요소를 비교하여 정렬 상태를 확인하는 조건문 (if, else, elif)을 사용하세요.\\n3. 배열을 순회하며 검사를 수행하는 루프 (for loop 또는 while loop)를 사용하세요.\\n4. 정렬되었는지 여부를 반환하는 값 (True 또는 False)을 반환하는 함수입니다.\",\n",
      "            \"key_concepts\": [\"Functions\", \"Conditionals\", \"Loops\", \"Algorithm efficiency\"]\n",
      "        }\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "    \t{\n",
      "\t\"question\": \"다음 과제는 여러 개의 세션에서 배운 주요 개념을 조합하여 풀어야 합니다. Python을 사용하여 아래의 요구 사항을 만족하는 프로그램을 작성하십시오.\\n\\n1. 사용자로부터 여러 개의 정수를 입력받아 리스트에 저장하십시오. (세션: '기본 데이터 구조: 리스트와 튜플')\\n2. 리스트에 있는 숫자 중에서 가장 큰 값을 찾기 위해 'for 루프'를 사용하여 탐색 알고리즘을 구현하십시오. (세션: '제어 구조: 루프', '탐색 알고리즘')\\n3. 입력받은 정수 리스트를 오름차순으로 정렬하기 위해 '버블 정렬' 알고리즘을 사용하십시오. (세션: '정렬 알고리즘')\\n4. 정렬된 리스트의 중간 값을 출력하십시오. 만약 리스트의 길이가 짝수라면, 중간 두 값의 평균을 출력하십시오. (세션: '기본 데이터 구조: 리스트와 튜플')\\n5. 이 모든 과정을 하나의 함수 안에서 처리하고, 해당 함수의 반환값으로 최종 결과를 출력하십시오. (세션: '함수: 정의와 사용')\\n\\n이 프로그램을 작성한 후, 각 단계에서 어떤 프로그래밍 개념이 사용되었는지 설명하는 주석을 추가하십시오. \",\n",
      "\t\"keywords\": [\n",
      "\t\t\"리스트와 튜플\",\n",
      "\t\t\"제어 구조: 루프\",\n",
      "\t\t\"탐색 알고리즘\",\n",
      "\t\t\"정렬 알고리즘\",\n",
      "\t\t\"함수: 정의와 사용\"\n",
      "\t]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(questions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명령어 생성 함수\n",
    "def generate_instructions(syllabus, num_questions=5):\n",
    "    questions = []\n",
    "    for _ in range(num_questions):\n",
    "        prompt = f\"\"\"\n",
    "        Generate a homework question based on the following syllabus:\n",
    "        \n",
    "        {syllabus}\n",
    "        \n",
    "        The question should be challenging and cover multiple key concepts from the syllabus.\n",
    "        \"\"\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=200,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        question = response.choices[0].text.strip()\n",
    "        questions.append(question)\n",
    "    \n",
    "    instructions = []\n",
    "    for question in questions:\n",
    "        prompt = f\"\"\"\n",
    "        Here is a homework question:\n",
    "        \n",
    "        {question}\n",
    "        \n",
    "        Provide a detailed answer to the question.\n",
    "        \"\"\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].text.strip()\n",
    "        instructions.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "    \n",
    "    return instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_syllabus(subject, level, subtopics):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in creating educational syllabi. Create a detailed syllabus for the subject \"{subject}\" at the {level} level. \n",
    "    The syllabus should be broken down into multiple class sessions, each covering different key concepts. \n",
    "    The subtopics for this subject include: {subtopics}. Provide the syllabus in JSON format with the following structure:\n",
    "    [\n",
    "        {{\n",
    "            \"session_name\": \"Session 1 Name\",\n",
    "            \"description\": \"Brief description of the session\",\n",
    "            \"key_concepts\": [\"Key concept 1\", \"Key concept 2\", ...]\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    syllabus = response.choices[0].text.strip()\n",
    "    try:\n",
    "        syllabus_json = json.loads(syllabus)\n",
    "    except json.JSONDecodeError:\n",
    "        syllabus_json = {\"error\": \"Failed to parse JSON\"}\n",
    "    return syllabus_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "# Taxonomy 생성 함수\n",
    "def generate_taxonomy():\n",
    "    prompt = \"\"\"\n",
    "    Create a taxonomy of human knowledge and capabilities. Break it down into fields, sub-fields, and disciplines.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    taxonomy = response.choices[0].text.strip()\n",
    "    try:\n",
    "        taxonomy_json = json.loads(taxonomy)\n",
    "    except json.JSONDecodeError:\n",
    "        taxonomy_json = {\"error\": \"Failed to parse JSON\"}\n",
    "    return taxonomy_json\n",
    "\n",
    "# 과목 생성 함수\n",
    "def generate_subjects(discipline):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in {discipline}. Create a comprehensive list of subjects a student should learn under this discipline. For each subject, provide the level (e.g., undergraduate, graduate) and include key subtopics. Present the result in JSON format.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    subjects = response.choices[0].text.strip()\n",
    "    try:\n",
    "        subjects_json = json.loads(subjects)\n",
    "    except json.JSONDecodeError:\n",
    "        subjects_json = {\"error\": \"Failed to parse JSON\"}\n",
    "    return subjects_json\n",
    "\n",
    "# 커리큘럼 생성 함수\n",
    "def generate_syllabus(subject, level, subtopics):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in creating educational syllabi. Create a detailed syllabus for the subject \"{subject}\" at the {level} level. The syllabus should be broken down into multiple class sessions, each covering different key concepts. The subtopics for this subject include: {subtopics}. Provide the syllabus in JSON format with the following structure:\n",
    "    [\n",
    "        {{\n",
    "            \"session_name\": \"Session 1 Name\",\n",
    "            \"description\": \"Brief description of the session\",\n",
    "            \"key_concepts\": [\"Key concept 1\", \"Key concept 2\", ...]\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    syllabus = response.choices[0].text.strip()\n",
    "    try:\n",
    "        syllabus_json = json.loads(syllabus)\n",
    "    except json.JSONDecodeError:\n",
    "        syllabus_json = {\"error\": \"Failed to parse JSON\"}\n",
    "    return syllabus_json\n",
    "\n",
    "# 명령어 생성 함수\n",
    "def generate_instructions(syllabus, num_questions=5):\n",
    "    questions = []\n",
    "    for _ in range(num_questions):\n",
    "        prompt = f\"\"\"\n",
    "        Generate a homework question based on the following syllabus:\n",
    "        \n",
    "        {syllabus}\n",
    "        \n",
    "        The question should be challenging and cover multiple key concepts from the syllabus.\n",
    "        \"\"\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=200,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        question = response.choices[0].text.strip()\n",
    "        questions.append(question)\n",
    "    \n",
    "    instructions = []\n",
    "    for question in questions:\n",
    "        prompt = f\"\"\"\n",
    "        Here is a homework question:\n",
    "        \n",
    "        {question}\n",
    "        \n",
    "        Provide a detailed answer to the question.\n",
    "        \"\"\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].text.strip()\n",
    "        instructions.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "    \n",
    "    return instructions\n",
    "\n",
    "# Algorithm 1 구현\n",
    "def glan_instruction_generation():\n",
    "    # 1. Taxonomy 생성\n",
    "    taxonomy = generate_taxonomy()\n",
    "    if \"error\" in taxonomy:\n",
    "        print(\"Error generating taxonomy:\", taxonomy[\"error\"])\n",
    "        return\n",
    "    \n",
    "    instructions_list = []\n",
    "    \n",
    "    # 2. 각 학문 분야에 대해 처리\n",
    "    for discipline in taxonomy.get('disciplines', []):\n",
    "        # 3. 과목 생성\n",
    "        subjects = generate_subjects(discipline)\n",
    "        if \"error\" in subjects:\n",
    "            print(f\"Error generating subjects for {discipline}:\", subjects[\"error\"])\n",
    "            continue\n",
    "        \n",
    "        for subject_data in subjects:\n",
    "            subject = subject_data[\"subject_name\"]\n",
    "            level = subject_data[\"level\"]\n",
    "            subtopics = \", \".join(subject_data[\"subtopics\"])\n",
    "            \n",
    "            # 4. 커리큘럼 생성\n",
    "            syllabus = generate_syllabus(subject, level, subtopics)\n",
    "            if \"error\" in syllabus:\n",
    "                print(f\"Error generating syllabus for {subject}:\", syllabus[\"error\"])\n",
    "                continue\n",
    "            \n",
    "            # 5. 명령어 생성\n",
    "            instructions = generate_instructions(json.dumps(syllabus))\n",
    "            instructions_list.extend(instructions)\n",
    "    \n",
    "    return instructions_list\n",
    "\n",
    "# 실행\n",
    "instructions_list = glan_instruction_generation()\n",
    "for i, instruction in enumerate(instructions_list):\n",
    "    print(f\"Instruction {i+1}:\\nQuestion: {instruction['question']}\\nAnswer: {instruction['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, shutil, random\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "raw_data_dir = \"raw_data\"\n",
    "splitted_raw_data_dir = f\"splitted_{raw_data_dir}\"\n",
    "\n",
    "#file_path = f\"{raw_data_dir}/prod-unst-pdf/[Sales Talk] 3. QnA3_Handling Objection_(S24)_240227.pdf\"\n",
    "file_path = f\"{raw_data_dir}/prod-unst-pdf/SM-S92X_UG_UU_Kor_Rev.1.1_240129.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "# Open the first PDF document\n",
    "doc1 = fitz.open(file_path)\n",
    "split_pages = [(1, 15)]\n",
    "\n",
    "for idx, s in enumerate(split_pages):\n",
    "    # Create a new empty PDF document\n",
    "    doc2 = fitz.open()\n",
    "\n",
    "    # Insert the first 2 pages of doc1 into doc2\n",
    "    doc2.insert_pdf(doc1, from_page=s[0], to_page=s[1])\n",
    "\n",
    "    # Save the modified document\n",
    "    doc2.save(f\"{raw_data_dir}/prod-unst-pdf/s24-user-manual-part{idx}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.common_utils import delete_folder_and_make_folder\n",
    "from util.preprocess import remove_short_sentences, remove_small_images, analyze_pdf_page_content, split_pdf\n",
    "\n",
    "file_path = f\"{raw_data_dir}/prod-unst-pdf/s24-user-manual-part0.pdf\"\n",
    "result = analyze_pdf_page_content(file_path)\n",
    "delete_folder_and_make_folder(splitted_raw_data_dir)    \n",
    "\n",
    "print(\"### PDF Content Analysis Result:\")\n",
    "for content_type, pages in result.items():\n",
    "    print(f\"{content_type} pages: {pages}\")\n",
    "    split_pdf(file_path, f\"{splitted_raw_data_dir}/{content_type}.pdf\", pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import ContentFormat\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "doc_intelligence_endpoint = os.getenv(\"AZURE_DOC_INTELLIGENCE_ENDPOINT\")\n",
    "doc_intelligence_key = os.getenv(\"AZURE_DOC_INTELLIGENCE_KEY\")\n",
    "\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=doc_intelligence_endpoint, \n",
    "    credential=AzureKeyCredential(doc_intelligence_key),\n",
    "    headers={\"x-ms-useragent\":\"sample-code-figure-understanding/1.0.0\"},\n",
    ")\n",
    "\n",
    "aoai_api_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "aoai_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=aoai_api_key,  \n",
    "    api_version=aoai_api_version,\n",
    "    base_url=f\"{aoai_api_endpoint}/openai/deployments/{aoai_deployment_name}\",\n",
    "    max_retries=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Mixed page (Images and text mixed appropriately)\n",
    "After reading the document with Azure AI Document Intelligence, we replace the image descriptions inside the figure tags with text summarized by a multimodal LLM. (Often the image descriptions are blank or have only a short caption.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_mixed_path = f\"{splitted_raw_data_dir}/Mixed.pdf\"\n",
    "\n",
    "with open(pdf_mixed_path, \"rb\") as f:\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\", analyze_request=f, content_type=\"application/octet-stream\", \n",
    "        output_content_format=ContentFormat.MARKDOWN \n",
    "    )\n",
    "\n",
    "result = poller.result()\n",
    "md_content = result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updates the content of the figure description (empty content or caption) with the image summary text generated by gpt-4o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from util.preprocess import (\n",
    "    image_complexity, is_bounding_box_larger_than, crop_image_from_file, \n",
    "    understand_image_with_gpt, update_figure_description\n",
    ")\n",
    "output_folder = \"pdf_mixed_tmp\"\n",
    "delete_folder_and_make_folder(output_folder)\n",
    "language = \"Korean\"\n",
    "max_tokens = 1024\n",
    "input_file_path = file_path\n",
    "\n",
    "if result.figures:\n",
    "    print(\"Figures:\")\n",
    "    for idx, figure in enumerate(result.figures):\n",
    "        figure_content = \"\"\n",
    "        img_description = \"\"\n",
    "        #print(f\"Figure #{idx} has the following spans: {figure.spans}\")\n",
    "        \n",
    "        for i, span in enumerate(figure.spans):\n",
    "            #print(f\"Span #{i}: {span}\")\n",
    "            figure_content += md_content[span.offset:span.offset + span.length]\n",
    "        #print(f\"Original figure content in markdown: {figure_content}\")\n",
    "\n",
    "        # Note: figure bounding regions currently contain both the bounding region of figure caption and figure body\n",
    "        if figure.caption:\n",
    "            caption_region = figure.caption.bounding_regions\n",
    "            #print(f\"\\tCaption: {figure.caption.content}\")\n",
    "            #print(f\"\\tCaption bounding region: {caption_region}\")\n",
    "            for region in figure.bounding_regions:\n",
    "                if region not in caption_region:\n",
    "                    #print(f\"\\tFigure body bounding regions: {region}\")\n",
    "                    # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "                    boundingbox = (\n",
    "                            region.polygon[0],  # x0 (left)\n",
    "                            region.polygon[1],  # y0 (top)\n",
    "                            region.polygon[4],  # x1 (right)\n",
    "                            region.polygon[5]   # y1 (bottom)\n",
    "                        )\n",
    "\n",
    "                    if is_bounding_box_larger_than(boundingbox):\n",
    "                        #print(f\"\\tFigure body bounding box in (x0, y0, x1, y1): {boundingbox}\")\n",
    "                        cropped_image = crop_image_from_file(input_file_path, region.page_number - 1, boundingbox) # page_number is 1-indexed\n",
    "\n",
    "                        if image_complexity(cropped_image)[0] == \"Complex\":\n",
    "                            # Get the base name of the file\n",
    "                            base_name = os.path.basename(input_file_path)\n",
    "                            # Remove the file extension\n",
    "                            file_name_without_extension = os.path.splitext(base_name)[0]\n",
    "\n",
    "                            output_file = f\"{file_name_without_extension}_cropped_image_{idx}.png\"\n",
    "                            cropped_image_filename = os.path.join(output_folder, output_file)\n",
    "\n",
    "                            cropped_image.save(cropped_image_filename)\n",
    "                            print(f\"\\tFigure {idx} cropped and saved as {cropped_image_filename}\")\n",
    "\n",
    "                            try: \n",
    "                                image_summarization = understand_image_with_gpt(client, aoai_deployment_name, cropped_image_filename, \"\", max_tokens=max_tokens, language=language)\n",
    "                            except openai.BadRequestError as e:\n",
    "                                print(f\"BadRequestError: {e}\")\n",
    "                                image_summarization = \"\"\n",
    "                            img_description += image_summarization\n",
    "\n",
    "                            print(f\"\\tDescription of figure {idx}: {img_description}\")\n",
    "                        else:\n",
    "                            print(f'simple image at idx {idx}')\n",
    "\n",
    "        else:\n",
    "            #print(\"\\tNo caption found for this figure.\")\n",
    "            for region in figure.bounding_regions:\n",
    "                #print(f\"\\tFigure body bounding regions: {region}\")\n",
    "                # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "                boundingbox = (\n",
    "                        region.polygon[0],  # x0 (left)\n",
    "                        region.polygon[1],  # y0 (top\n",
    "                        region.polygon[4],  # x1 (right)\n",
    "                        region.polygon[5]   # y1 (bottom)\n",
    "                    )\n",
    "\n",
    "                if is_bounding_box_larger_than(boundingbox):                    \n",
    "                    #print(f\"\\tFigure body bounding box in (x0, y0, x1, y1): {boundingbox}\")\n",
    "\n",
    "                    cropped_image = crop_image_from_file(input_file_path, region.page_number - 1, boundingbox) # page_number is 1-indexed\n",
    "\n",
    "                    if image_complexity(cropped_image)[0] == \"Complex\":\n",
    "                        # Get the base name of the file\n",
    "                        base_name = os.path.basename(input_file_path)\n",
    "                        # Remove the file extension\n",
    "                        file_name_without_extension = os.path.splitext(base_name)[0]\n",
    "\n",
    "                        output_file = f\"{file_name_without_extension}_cropped_image_{idx}.png\"\n",
    "                        cropped_image_filename = os.path.join(output_folder, output_file)\n",
    "                        # cropped_image_filename = f\"data/cropped/image_{idx}.png\"\n",
    "                        cropped_image.save(cropped_image_filename)\n",
    "                        #print(f\"\\tFigure {idx} cropped and saved as {cropped_image_filename}\")\n",
    "\n",
    "                        try:\n",
    "                            image_summarization = understand_image_with_gpt(client, aoai_deployment_name, cropped_image_filename, \"\", max_tokens=max_tokens, language=language)\n",
    "                        except openai.BadRequestError as e:\n",
    "                            print(f\"BadRequestError: {e}\")\n",
    "                            image_summarization = \"\"\n",
    "                        img_description += image_summarization\n",
    "                        print(f\"\\tDescription of figure {idx}: {img_description}\")\n",
    "                    else:\n",
    "                        print(f'simple image at idx {idx}')\n",
    "\n",
    "        \n",
    "        md_content = update_figure_description(md_content, img_description, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, Markdown, Latex\n",
    "# display(Markdown(md_content[:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate chunks for mixed pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        r'<!-- PageNumber=\"\\d+\" -->',\n",
    "        r\"\\n\\n\",\n",
    "        r\"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \"\",\n",
    "    ],   \n",
    "    is_separator_regex = True,    \n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "mixed_chunks = text_splitter.split_text(md_content)\n",
    "print(\"Length of splits (mixed case): \" + str(len(mixed_chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Text-heavy\n",
    "Text-heavy PDFs can be processed with open source without the need to use toolkits like Azure AI Document Intelligence or Unstructured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "pdf_text_path = f\"{splitted_raw_data_dir}/Text.pdf\"\n",
    "loader = PyMuPDFLoader(pdf_text_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, \n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "for idx, chunk in enumerate(text_chunks):\n",
    "    print(f\"Chunk {idx}\\n{chunk}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "text_chunks = [d.page_content for d in text_chunks]\n",
    "print(\"Length of splits (text-heay case): \" + str(len(text_chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: Image-heavy\n",
    "Image-heavy PDF can be converted the entire page to images and let a multimodal LLM like GPT-4o summarize each page.\n",
    "\n",
    "### Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./pdf_image_tmp\"\n",
    "delete_folder_and_make_folder(image_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from glob import glob\n",
    "\n",
    "pdf_image_path = f\"{splitted_raw_data_dir}/Image.pdf\"\n",
    "doc = fitz.open(pdf_image_path)\n",
    "#clip_x, clip_y = 10, 45\n",
    "clip_x, clip_y = 10, 10\n",
    "\n",
    "for i, page in enumerate(doc):\n",
    "    x, y, w, h = page.rect\n",
    "    clip = fitz.Rect(x+clip_x, y+clip_y, w-clip_x, h-clip_y)\n",
    "    page.set_cropbox(clip)\n",
    "    pix = page.get_pixmap()\n",
    "    pix.save(f\"{image_dir}/page_{i:03d}.jpg\")\n",
    "\n",
    "images = sorted(glob(os.path.join(image_dir, \"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "max_tokens = 1024\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4o\"                       \n",
    ")\n",
    "\n",
    "system_prompt = \"You are an assistant tasked with describing table or image, specialized in Smartphone product.\"\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "human_prompt = [\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": \"data:image/png;base64,\" + \"{image_base64}\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": '''Given image, give a concise summary in Korean. Don't insert any XML tag such as <text> and </text> when answering.'''\n",
    "    },\n",
    "]\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_template,\n",
    "        human_message_template\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarize_chain = prompt | llm | StrOutputParser()\n",
    "#summarize_chain = {\"image_base64\": lambda x:x} | prompt | llm_text | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from util.preprocess import encode_image_base64\n",
    "#images = glob(os.path.join(image_path, \"*.jpg\"))\n",
    "base64_images = [encode_image_base64(img_path) for img_path in images]\n",
    "image_summaries = summarize_chain.batch(base64_images, {\"max_concurrency\": 8})\n",
    "image_summaries = remove_short_sentences(image_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of image_summaries (image-heavy case): \" + str(len(image_summaries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct QnA Pairs\n",
    "----\n",
    "\n",
    "### Option 1. \n",
    "Leverage the azure-ai-generative package. The QADataGenerator class in this package makes it easy to generate QnA synthetic questions. However, using this class as is has the disadvantage of not being able to use custom prompts, so we inherited from it and created the CustomQADataGenerator class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PubMedLoader\n",
    "\n",
    "loader = PubMedLoader(\"liver\", load_max_docs=10)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4\"                       \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4\"                       \n",
    ")\n",
    "\n",
    "\n",
    "critic_llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4o\"                       \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-3-large\", openai_api_version=\"2024-05-01-preview\")\n",
    "text = \"this is a test document\"\n",
    "\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "# documents = load your documents\n",
    "max_tokens=1024\n",
    "\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-3-large\", openai_api_version=\"2024-05-01-preview\")\n",
    "generator_llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4\"                       \n",
    ")\n",
    "\n",
    "\n",
    "critic_llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_version=\"2024-05-01-preview\",\n",
    "    azure_deployment=\"gpt-4o\"                       \n",
    ")\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/executor.py\", line 87, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/asyncio/base_events.py\", line 661, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/asyncio/base_events.py\", line 620, in _check_running\n",
      "    raise RuntimeError('This event loop is already running')\n",
      "RuntimeError: This event loop is already running\n",
      "/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/threading.py:1075: RuntimeWarning: coroutine 'Runner._aresults' was never awaited\n",
      "  self._invoke_excepthook(self)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     19\u001b[0m distributions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     simple: \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     21\u001b[0m     multi_context: \u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m     22\u001b[0m     reasoning: \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     23\u001b[0m }\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# testsetgenerator = TestsetGenerator(generator_llm=ragas_llm, critic_llm=ragas_llm,embeddings_model=embedding_function, testset_distribution=testset_distribution)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# test_size = 3\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# testset = testsetgenerator.generate(docs, test_size=test_size)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# generate testset\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# use generator.generate_with_llamaindex_docs if you use llama-index as document loader\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#testset = generator.generate_with_langchain_docs(documents, 5, distributions) \u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#testset = generator.generate(input_batch, test_size=5)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m testset\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/testset/generator.py:206\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    204\u001b[0m distributions \u001b[38;5;241m=\u001b[39m distributions \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_langchain_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    211\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size,\n\u001b[1;32m    212\u001b[0m     distributions\u001b[38;5;241m=\u001b[39mdistributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/testset/docstore.py:215\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_documents\u001b[0;34m(self, docs, show_progress)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# split documents with self.splitter into smaller nodes\u001b[39;00m\n\u001b[1;32m    211\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    212\u001b[0m     Node\u001b[38;5;241m.\u001b[39mfrom_langchain_document(d)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39mtransform_documents(docs)\n\u001b[1;32m    214\u001b[0m ]\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/testset/docstore.py:254\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_nodes\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    252\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nodes_to_embed\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daekeun/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ipykernel/iostream.py:123: RuntimeWarning: coroutine 'as_completed.<locals>.sema_coro' was never awaited\n",
      "  await self._event_pipe_gc()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# documents = load your documents\n",
    "\n",
    "# generator with openai models\n",
    "# generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "# critic_llm = ChatOpenAI(model=\"gpt-4\")\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=embeddings,\n",
    "    chunk_size=1024\n",
    ")\n",
    "# Change resulting question type distribution\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "# testsetgenerator = TestsetGenerator(generator_llm=ragas_llm, critic_llm=ragas_llm,embeddings_model=embedding_function, testset_distribution=testset_distribution)\n",
    "# test_size = 3\n",
    "# testset = testsetgenerator.generate(docs, test_size=test_size)\n",
    "\n",
    "\n",
    "\n",
    "# generate testset\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=5, distributions=distributions, raise_exceptions=False)\n",
    "\n",
    "# use generator.generate_with_llamaindex_docs if you use llama-index as document loader\n",
    "#testset = generator.generate_with_langchain_docs(documents, 5, distributions) \n",
    "#testset = generator.generate(input_batch, test_size=5)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/executor.py\", line 87, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/asyncio/base_events.py\", line 661, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"/Users/daekeun/.pyenv/versions/3.12.2/lib/python3.12/asyncio/base_events.py\", line 620, in _check_running\n",
      "    raise RuntimeError('This event loop is already running')\n",
      "RuntimeError: This event loop is already running\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/testset/generator.py:206\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    204\u001b[0m distributions \u001b[38;5;241m=\u001b[39m distributions \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_langchain_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    211\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size,\n\u001b[1;32m    212\u001b[0m     distributions\u001b[38;5;241m=\u001b[39mdistributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/testset/docstore.py:215\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_documents\u001b[0;34m(self, docs, show_progress)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# split documents with self.splitter into smaller nodes\u001b[39;00m\n\u001b[1;32m    211\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    212\u001b[0m     Node\u001b[38;5;241m.\u001b[39mfrom_langchain_document(d)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39mtransform_documents(docs)\n\u001b[1;32m    214\u001b[0m ]\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/ragas/testset/docstore.py:254\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_nodes\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    252\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nodes_to_embed\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(documents, test_size=5, distributions=distributions, raise_exceptions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.qa import CustomQADataGenerator\n",
    "model_config = {\n",
    "    \"deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"max_tokens\": 2000,\n",
    "}\n",
    "\n",
    "qa_generator = CustomQADataGenerator(model_config=model_config, templates_dir=\"./prompt_template/ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections import Counter\n",
    "from typing import Dict\n",
    "import os\n",
    "from azure.ai.generative.synthetic.qa import QAType\n",
    "concurrency = 6  # number of concurrent calls\n",
    "sem = asyncio.Semaphore(concurrency)\n",
    "\n",
    "#qa_type = QAType.CONVERSATION\n",
    "qa_type = QAType.LONG_ANSWER\n",
    "\n",
    "async def generate_async(text: str) -> Dict:\n",
    "    async with sem:\n",
    "        return await qa_generator.generate_async(\n",
    "            text=text,\n",
    "            qa_type=qa_type,\n",
    "            num_questions=3,  # Number of questions to generate per text\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = mixed_chunks + text_chunks + image_summaries\n",
    "results = await asyncio.gather(*[generate_async(text) for text in input_batch], return_exceptions=True)\n",
    "\n",
    "question_answer_list = []\n",
    "token_usage = Counter()\n",
    "for result in results:\n",
    "    if isinstance(result, Exception):\n",
    "        raise result  # exception raised inside generate_async()\n",
    "    question_answer_list.append(result[\"question_answers\"])\n",
    "    token_usage += result[\"token_usage\"]\n",
    "\n",
    "print(\"Successfully generated QAs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2. \n",
    "You write the entire sequence of code to create a QnA dataset without using a separate toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from util.qa_pair import get_qna_prompt_template, QAPair\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=1024,\n",
    "    openai_api_version=aoai_api_version,\n",
    "    azure_deployment=aoai_deployment_name                    \n",
    ")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=QAPair)\n",
    "prompt = get_qna_prompt_template()\n",
    "#prompt = get_qna_repair_cost_prompt_template()\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = []\n",
    "\n",
    "for doc in mixed_chunks:\n",
    "    dic = {\"context\": doc, \"domain\": \"Samsung Galaxy S series Smartphone, especially S23 and S24 series\", \"num_questions\": \"3\"}\n",
    "    input_batch.append(dic)\n",
    "\n",
    "for doc in text_chunks:\n",
    "    dic = {\"context\": doc, \"domain\": \"Samsung Galaxy S series Smartphone, especially S23 and S24 series\", \"num_questions\": \"3\"}\n",
    "    input_batch.append(dic)\n",
    "\n",
    "for doc in image_summaries:\n",
    "    dic = {\"context\": doc, \"domain\": \"Samsung Galaxy S series Smartphone, especially S23 and S24 series\", \"num_questions\": \"3\"}\n",
    "    input_batch.append(dic)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#input_query = {\"context\": md_content, \"domain\": \"Samsung Galaxy S series Smartphone\", \"num_questions\": \"3\"}\n",
    "qa_pair = chain.batch(input_batch, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save to jsonl for fine-tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(qa_pair, f\"{output_dir}/{save_filename}.jsonl\")\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from util.common_utils import convert_to_oai_format, save_jsonl\n",
    "\n",
    "output_dir = './dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "system_prompt_msg = \"\"\"You are an AI assistant that provides guidance to help users self-service resolve abnormalities in their Galaxy mobile phone.\\n\n",
    "Please answer the questions accurately. If the question is in Korean, write your answer in Korean. If the question is in English, write your answer in English.\"\"\"\n",
    "\n",
    "save_filename = \"cs-self-solve\"\n",
    "oai_qa_pair = convert_to_oai_format(question_answer_list)\n",
    "\n",
    "#save_jsonl(qa_pair, f\"{output_dir}/{save_filename}.jsonl\")\n",
    "save_jsonl(oai_qa_pair, f\"{output_dir}/{save_filename}-oai.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {splitted_raw_data_dir} pdf_image_tmp pdf_mixed_tmp outputs_tmp images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
